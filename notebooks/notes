# sortedData.loc[sortedData['visitorId'] == '00329289-e63b-4bdb-9bb8-2da62161c353']
# path = "/Users/george/Expendable/gaming.json"
# path2 = "/Users/george/Expendable/sampleSmall.json"
# path3 = "/Users/george/Expendable/sample.json"


import json

class JsonProcessor:

    def json_read(self, filepath):
        with open(filepath) as f:
            for line in f:
                j_content = json.loads(line)
        return j_content


        # km = KPrototypes(n_clusters=4, init='Cao', verbose=16)

# clusters = km.fit_predict(sortedData, categorical=categoricalData)

# print(km.cluster_centroids_)



#categoricalData = ["audience", "visitorId", "channel", "url", "geo", "newVisit"]

with open(filePath) as f:
    file = json.load(f)
    normalisedFile = json_normalize(file)

sortedData1 = jsonTools.json_sort(normalisedFile, sortBy)

#To take out pageUrl's that end with '.png' or '.jpeg' --> sortedData[~sortedData['pageUrl'].str.endswith('.png')]

df1 = pd.DataFrame(data={'id': [1, 2, 2, 2, 3, 4, 5, 6, 7, 7, 7, 7, 7, 8],
                         'timestamp': [11, 21, 22, 23, 31, 41, 51, 61, 71, 72, 73, 74, 75, 81],
                         'whatev': [42, 42, 11, 11, 42, 11, 42, 42, 42, 11, 11, 11, 11, 42],
                         'whatev2': [42, 42, 11, 11, 42, 11, 42, 42, 42, 11, 11, 11, 11, 42]})

df2 = pd.DataFrame(data={'id': [1, 2, 3, 5, 6, 7, 8], 'timestamp': [11, 21, 31, 51, 61, 71, 81],
                         'suresure': [22, 22, 22, 22, 22, 22, 22], 'heyhey': [22, 22, 22, 22, 22, 22, 22]})


droplist = ['geo.latitude','geo.location.lat','geo.location.lon','geo.longitude', 'journeypersona.terms', 'pageviews','globalPersonaIdScores','personaIdScores','audience.terms', 'categories.terms']
finaldf = final_dataframe.drop(droplist, axis=1)


############## Print clustering results if needd
# Print cluster centroids of the trained model.
print('k-modes (Huang) centroids:')
print(kmodes_huang.cluster_centroids_)
# Print training statistics
print('Final training cost: {}'.format(kmodes_huang.cost_))
print('Training iterations: {}'.format(kmodes_huang.n_iter_))


############# Normalize collectors and drop columns
        # collector_data = json_normalize(data_frame['collectorData'])
        # all_data = pd.concat([collector_data, data_frame], axis=1)
        # processed_data = all_data.drop(droplist, axis=1)


####### split list into columns

s = data_frame.transactionPath.apply(lambda x: pd.Series(x)).unstack()
df2 = data_frame.join(pd.DataFrame(s.reset_index(level=0, drop=True)))
      .drop('transactionPath',1).rename(columns={0:'transactionPath'})
df2 = df2[pd.notnull(df2['transactionPath'])]
df = df2.merge(pd.get_dummies(df2.transactionPath), left_index=True, right_index=True)
     .drop('transactionPath',1)

####### way 2
df1 = pd.get_dummies(pd.DataFrame(data_frame.transactionPath.values.tolist()), prefix='', prefix_sep='').groupby(axis=1, level=0).max()
df2 = pd.concat([data_frame, df1], axis = 1)

####### silhouette
a = pd.DataFrame.from_csv("/Users/george/PycharmProjects/scikitLiterallyLearn/segmentation/dataFiles/distancematrix.csv")
b = kmodes_cao.labels_
silhouette_score(a,b, metric = 'precomputed')

or

a = pd.read_csv(
    "/Users/george/PycharmProjects/scikitLiterallyLearn/segmentation/dataFiles/8juneSmallPCM.csv")
b = kmodes_cao.labels_
print("Silhouette score:", silhouette_score(a, b, metric='precomputed'))

###### Keep the content pages
data_frame['contentPage']= data_frame.transactionPath.str[-1]